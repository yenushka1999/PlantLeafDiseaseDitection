{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN5FxtdpCiOuXPYohUjQbuM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"KZM9qfy9YFWr"},"outputs":[],"source":["# ---------------------------\n","# Cell 1: Install & Imports\n","# ---------------------------\n","!pip install tensorflow matplotlib pandas scikit-learn pillow --quiet\n","\n","import os, zipfile, shutil, random\n","from pathlib import Path\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from tensorflow.keras import layers, models, optimizers\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n","from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n","from PIL import Image\n","\n","# Optional mixed precision\n","try:\n","    from tensorflow.keras import mixed_precision\n","    mixed_precision.set_global_policy('mixed_float16')\n","except:\n","    pass\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MpF68DxnY0Ig"},"outputs":[],"source":["# ---------------------------\n","# Cell 2: Mount Drive & unzip dataset\n","# ---------------------------\n","from google.colab import drive, files\n","import zipfile\n","import os\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Paths\n","DRIVE_ZIP_PATH = '/content/drive/MyDrive/DataSetPlantDiseases.zip'\n","EXTRACTED_ROOT = '/content/plant_disease_data'\n","\n","# Extract ZIP if not already done\n","if not os.path.exists(EXTRACTED_ROOT):\n","    os.makedirs(EXTRACTED_ROOT, exist_ok=True)\n","    with zipfile.ZipFile(DRIVE_ZIP_PATH, 'r') as zip_ref:\n","        zip_ref.extractall(EXTRACTED_ROOT)\n","    print(f\"‚úÖ Dataset extracted to {EXTRACTED_ROOT}\")\n","else:\n","    print(f\"‚úÖ Dataset already exists at {EXTRACTED_ROOT}\")\n"]},{"cell_type":"code","source":[],"metadata":{"id":"AomVEX5Wg0dm"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5UVBtsbKZKph"},"outputs":[],"source":["# ---------------------------\n","# Cell 2a: Clean & smaller dataset creation\n","# ---------------------------\n","import random, shutil\n","\n","SMALL_ROOT = '/content/plant_disease_data_small'\n","MAX_IMAGES_PER_CLASS = 100  # max images per class\n","\n","# Step 1: Remove hidden files\n","for root, dirs, files_in_dir in os.walk(EXTRACTED_ROOT):\n","    for f in files_in_dir:\n","        if f.startswith('.') or f.lower() == 'thumbs.db':\n","            os.remove(os.path.join(root, f))\n","\n","# Step 2: Detect dataset folder structure\n","ROOT_DIR = EXTRACTED_ROOT\n","for sub in os.listdir(EXTRACTED_ROOT):\n","    path = os.path.join(EXTRACTED_ROOT, sub)\n","    if os.path.isdir(path):\n","        subfolders = os.listdir(path)\n","        if all(f in subfolders for f in ['train', 'valid', 'test']):\n","            ROOT_DIR = path\n","            print(f\"‚úÖ Dataset folder found: {ROOT_DIR}\")\n","            break\n","\n","# Step 3: Create smaller dataset\n","folders = ['train', 'valid', 'test']\n","for folder in folders:\n","    src_folder = os.path.join(ROOT_DIR, folder)\n","    dst_folder = os.path.join(SMALL_ROOT, folder)\n","    os.makedirs(dst_folder, exist_ok=True)\n","\n","    class_dirs = [d for d in os.listdir(src_folder) if os.path.isdir(os.path.join(src_folder, d))]\n","\n","    for class_name in class_dirs:\n","        class_src = os.path.join(src_folder, class_name)\n","        class_dst = os.path.join(dst_folder, class_name)\n","        os.makedirs(class_dst, exist_ok=True)\n","\n","        all_images = [f for f in os.listdir(class_src) if os.path.isfile(os.path.join(class_src, f))]\n","        selected_images = random.sample(all_images, min(MAX_IMAGES_PER_CLASS, len(all_images)))\n","\n","        for img in selected_images:\n","            shutil.copy(os.path.join(class_src, img), os.path.join(class_dst, img))\n","\n","print(f\"‚úÖ Smaller dataset created at {SMALL_ROOT}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OpeFei7kZQz3"},"outputs":[],"source":["# ---------------------------\n","# Cell 3: Train/Valid/Test directories\n","# ---------------------------\n","\n","ROOT_DIR = SMALL_ROOT\n","\n","train_dir = os.path.join(ROOT_DIR, 'train')\n","val_dir   = os.path.join(ROOT_DIR, 'valid')\n","test_dir  = os.path.join(ROOT_DIR, 'test')\n","\n","# Verify existence\n","for folder in [train_dir, val_dir, test_dir]:\n","    if not os.path.exists(folder):\n","        raise FileNotFoundError(f\"Folder not found: {folder}\")\n","    else:\n","        print(f\"‚úÖ Found folder: {folder}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CvfYcIBEZV2-"},"outputs":[],"source":["# ---------------------------\n","# Cell 4: Data Generators\n","# ---------------------------\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","IMAGE_SIZE = (224, 224)\n","BATCH_SIZE = 32\n","SEED = 123\n","\n","# Training generator with strong augmentation\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=40,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")\n","\n","# Validation / Test generator\n","val_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# Generators\n","train_gen = train_datagen.flow_from_directory(\n","    train_dir,\n","    target_size=IMAGE_SIZE,\n","    batch_size=BATCH_SIZE,\n","    class_mode='categorical',\n","    shuffle=True,\n","    seed=SEED\n",")\n","\n","val_gen = val_datagen.flow_from_directory(\n","    val_dir,\n","    target_size=IMAGE_SIZE,\n","    batch_size=BATCH_SIZE,\n","    class_mode='categorical',\n","    shuffle=False,\n","    seed=SEED\n",")\n","\n","test_gen = val_datagen.flow_from_directory(\n","    test_dir,\n","    target_size=IMAGE_SIZE,\n","    batch_size=BATCH_SIZE,\n","    class_mode='categorical',\n","    shuffle=False,\n","    seed=SEED\n",")\n","\n","# Dynamically detect number of classes\n","NUM_CLASSES = len(train_gen.class_indices)\n","print(f\"‚úÖ Number of classes detected: {NUM_CLASSES}\")\n"]},{"cell_type":"code","source":[],"metadata":{"id":"lZgu93tJhHzf"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v7O4fSjQZacT"},"outputs":[],"source":["# ---------------------------\n","# Cell 5: Model Compilation & Evaluation\n","# ---------------------------\n","\n","from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n","import numpy as np\n","from tensorflow.keras import optimizers\n","\n","def compile_and_summary(model, lr=1e-3):\n","    model.compile(\n","        optimizer=optimizers.Adam(lr),\n","        loss='categorical_crossentropy',\n","        metrics=['accuracy']\n","    )\n","    model.summary()\n","\n","def evaluate_model_on_generator(model, generator):\n","    steps = int(np.ceil(generator.samples / generator.batch_size))\n","    preds = model.predict(generator, steps=steps, verbose=1)\n","\n","    y_pred = np.argmax(preds, axis=1)\n","    y_true = generator.classes[:len(y_pred)]\n","    labels = list(generator.class_indices.keys())\n","\n","    report = classification_report(y_true, y_pred, target_names=labels, zero_division=0, output_dict=True)\n","\n","    acc = accuracy_score(y_true, y_pred)\n","    prec = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n","    rec = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n","    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n","\n","    return {\n","        'accuracy': acc,\n","        'precision': prec,\n","        'recall': rec,\n","        'f1': f1,\n","        'report': report,\n","        'y_true': y_true,\n","        'y_pred': y_pred,\n","        'labels': labels\n","    }\n","\n","print(\"‚úÖ Utility functions ready\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XydPfmQ18wk_"},"outputs":[],"source":["# ---------------------------\n","# Cell 6: Model A Training (MobileNetV2) + Save to Google Drive (Timestamped)\n","# ---------------------------\n","\n","from tensorflow.keras.applications import MobileNetV2\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n","import os, shutil, datetime\n","\n","# Base model\n","base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1],3))\n","base_model.trainable = False\n","\n","# Custom head\n","x = layers.GlobalAveragePooling2D()(base_model.output)\n","x = layers.Dense(256, activation='relu')(x)\n","x = layers.Dropout(0.4)(x)\n","outputs = layers.Dense(NUM_CLASSES, activation='softmax', dtype='float32')(x)\n","\n","model_a = models.Model(inputs=base_model.input, outputs=outputs)\n","compile_and_summary(model_a, lr=1e-3)\n","\n","# Create timestamp\n","timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","\n","# File paths\n","final_model_drive = f\"/content/drive/MyDrive/model_a_final_{timestamp}.h5\"\n","best_model_colab = f\"/content/model_a_best_{timestamp}.h5\"\n","best_model_drive = f\"/content/drive/MyDrive/model_a_best_{timestamp}.h5\"\n","\n","# Callbacks\n","callbacks = [\n","    EarlyStopping(patience=3, restore_best_weights=True, monitor='val_loss'),\n","    ReduceLROnPlateau(patience=2, factor=0.5, monitor='val_loss', verbose=1),\n","    ModelCheckpoint(best_model_colab, save_best_only=True, monitor='val_loss')\n","]\n","\n","# üö® Run training only once\n","if 'history_a' not in globals():\n","    print(\"‚ñ∂Ô∏è Starting training for 5 epochs...\")\n","    history_a = model_a.fit(\n","        train_gen,\n","        epochs=5,\n","        validation_data=val_gen,\n","        callbacks=callbacks,\n","        verbose=1\n","    )\n","    print(\"‚úÖ Training finished\")\n","\n","    # Save final model\n","    model_a.save(final_model_drive)\n","    print(f\"üíæ Final model saved to {final_model_drive}\")\n","\n","    # Save best checkpoint\n","    shutil.copy(best_model_colab, best_model_drive)\n","    print(f\"üèÜ Best checkpoint saved to {best_model_drive}\")\n","\n","else:\n","    print(\"‚ö†Ô∏è Training already done. Skip re-run.\")\n"]},{"cell_type":"code","source":[],"metadata":{"id":"OZIlxmbF1V-3"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6lOll8AX97bh"},"outputs":[],"source":["# ---------------------------\n","# Cell 7: Save existing trained model to Google Drive\n","# ---------------------------\n","\n","from google.colab import drive\n","import shutil\n","import os\n","import datetime\n","\n","# 1Ô∏è‚É£ Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# 2Ô∏è‚É£ Create timestamp\n","timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","\n","# 3Ô∏è‚É£ Source files in Colab (from last training run)\n","colab_final_model = \"/content/model_a_final.h5\"   # change if your model has a different name\n","colab_best_model  = \"/content/model_a_best.h5\"\n","\n","# 4Ô∏è‚É£ Destination paths in Drive\n","drive_final_model = f\"/content/drive/MyDrive/model_a_final_{timestamp}.h5\"\n","drive_best_model  = f\"/content/drive/MyDrive/model_a_best_{timestamp}.h5\"\n","\n","# 5Ô∏è‚É£ Copy files to Drive\n","if os.path.exists(colab_final_model):\n","    shutil.copy(colab_final_model, drive_final_model)\n","    print(f\"‚úÖ Final model saved to Drive: {drive_final_model}\")\n","else:\n","    print(\"‚ö†Ô∏è Final model not found in Colab.\")\n","\n","if os.path.exists(colab_best_model):\n","    shutil.copy(colab_best_model, drive_best_model)\n","    print(f\"üèÜ Best checkpoint saved to Drive: {drive_best_model}\")\n","else:\n","    print(\"‚ö†Ô∏è Best checkpoint not found in Colab.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gvJ892r4-mNe"},"outputs":[],"source":["# Save the final trained model manually\n","import datetime\n","\n","timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","final_model_drive = f\"/content/drive/MyDrive/model_a_final_{timestamp}.h5\"\n","\n","model_a.save(final_model_drive)\n","print(f\"üíæ Final model saved to Drive: {final_model_drive}\")\n"]},{"cell_type":"code","source":[],"metadata":{"id":"Y5yoFmU_2fVY"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"4Rq77c68_0pg"},"outputs":[],"source":["# Resume training for additional epochs\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n","import datetime, shutil, os\n","\n","# Current model is already loaded in `model_a`\n","# Number of additional epochs\n","additional_epochs = 3\n","\n","# Create timestamp for new files\n","timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","\n","# File paths for saving\n","best_model_colab = f\"/content/model_a_best_{timestamp}.h5\"\n","final_model_drive = f\"/content/drive/MyDrive/model_a_final_{timestamp}.h5\"\n","\n","# Callbacks\n","callbacks = [\n","    EarlyStopping(patience=3, restore_best_weights=True, monitor='val_loss'),\n","    ReduceLROnPlateau(patience=2, factor=0.5, monitor='val_loss', verbose=1),\n","    ModelCheckpoint(best_model_colab, save_best_only=True, monitor='val_loss')\n","]\n","\n","# Resume training\n","history_resume = model_a.fit(\n","    train_gen,\n","    epochs=additional_epochs,\n","    validation_data=val_gen,\n","    callbacks=callbacks\n",")\n","\n","# Save updated models to Drive\n","model_a.save(final_model_drive)\n","shutil.copy(best_model_colab, f\"/content/drive/MyDrive/{os.path.basename(best_model_colab)}\")\n","\n","print(f\"‚úÖ Resumed training completed. Final model saved as: {final_model_drive}\")\n","print(f\"üèÜ Best checkpoint saved as: /content/drive/MyDrive/{os.path.basename(best_model_colab)}\")\n"]},{"cell_type":"code","source":[],"metadata":{"id":"jqwgiR302nMg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ---------------------------\n","# Cell 8: Ultra-Lightweight CNN + Fast Training + Auto Save to Drive\n","# ---------------------------\n","\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n","from google.colab import drive\n","import os, datetime, pickle\n","\n","# 1Ô∏è‚É£ Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# 2Ô∏è‚É£ Build ultra-light CNN\n","inputs = layers.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n","\n","x = layers.Conv2D(16, (3,3), activation='relu', padding='same')(inputs)\n","x = layers.MaxPooling2D((2,2))(x)\n","\n","x = layers.Conv2D(32, (3,3), activation='relu', padding='same')(x)\n","x = layers.MaxPooling2D((2,2))(x)\n","\n","x = layers.Conv2D(64, (3,3), activation='relu', padding='same')(x)\n","x = layers.GlobalAveragePooling2D()(x)\n","\n","x = layers.Dense(64, activation='relu')(x)\n","x = layers.Dropout(0.2)(x)\n","\n","outputs = layers.Dense(NUM_CLASSES, activation='softmax', dtype='float32')(x)\n","\n","model_b = models.Model(inputs, outputs)\n","\n","# 3Ô∏è‚É£ Compile\n","compile_and_summary(model_b, lr=0.002)\n","\n","# 4Ô∏è‚É£ Callbacks with Drive saving\n","timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","SAVE_DIR = '/content/drive/MyDrive'\n","best_model_file = os.path.join(SAVE_DIR, f'model_b_best_{timestamp}.h5')\n","final_model_file = os.path.join(SAVE_DIR, f'model_b_final_{timestamp}.h5')\n","history_file = os.path.join(SAVE_DIR, f'history_b_{timestamp}.pkl')\n","\n","callbacks = [\n","    EarlyStopping(patience=2, restore_best_weights=True, monitor='val_loss'),\n","    ReduceLROnPlateau(patience=1, factor=0.5, monitor='val_loss', verbose=1),\n","    ModelCheckpoint(best_model_file, save_best_only=True, monitor='val_loss')\n","]\n","\n","# 5Ô∏è‚É£ Train\n","history_b = model_b.fit(\n","    train_gen,\n","    epochs=5,      # ultra-short for speed\n","    validation_data=val_gen,\n","    batch_size=128,  # larger batch to reduce steps\n","    callbacks=callbacks\n",")\n","\n","# 6Ô∏è‚É£ Save final model & history\n","model_b.save(final_model_file)\n","with open(history_file, 'wb') as f:\n","    pickle.dump(history_b.history, f)\n","\n","print(f\"‚úÖ Model B final saved: {final_model_file}\")\n","print(f\"üèÜ Model B best checkpoint saved: {best_model_file}\")\n","print(f\"üìä Training history saved: {history_file}\")\n"],"metadata":{"id":"mXJ-IhqvAf44"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"_LEQX4PC2sXh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ---------------------------\n","# Cell: Evaluate Both Models & Compare Metrics\n","# ---------------------------\n","\n","import numpy as np\n","import pandas as pd\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","# ---------------------------\n","# Paths to models and test folder\n","# ---------------------------\n","MODEL_A_PATH = '/content/drive/MyDrive/model_a_best_20250930_050137.h5'  # MobileNet\n","MODEL_B_PATH = '/content/drive/MyDrive/model_b_best_20250930_083817.h5'  # Ultra-light CNN\n","TEST_DIR = '/content/drive/MyDrive/test'\n","BATCH_SIZE = 32\n","\n","# ---------------------------\n","# Load models\n","# ---------------------------\n","model_a = load_model(MODEL_A_PATH)\n","model_b = load_model(MODEL_B_PATH)\n","\n","# ---------------------------\n","# Test generators for correct image sizes\n","# ---------------------------\n","# Model A (MobileNet) - 224x224\n","test_gen_a = ImageDataGenerator(rescale=1./255).flow_from_directory(\n","    TEST_DIR,\n","    target_size=(224,224),\n","    batch_size=BATCH_SIZE,\n","    class_mode='categorical',\n","    shuffle=False\n",")\n","\n","# Model B (Ultra-light CNN) - 128x128\n","test_gen_b = ImageDataGenerator(rescale=1./255).flow_from_directory(\n","    TEST_DIR,\n","    target_size=(128,128),\n","    batch_size=BATCH_SIZE,\n","    class_mode='categorical',\n","    shuffle=False\n",")\n","\n","# ---------------------------\n","# Evaluation function\n","# ---------------------------\n","def get_metrics(model, test_gen):\n","    y_true = test_gen.classes\n","    y_pred = model.predict(test_gen, verbose=0)\n","    y_pred_classes = np.argmax(y_pred, axis=1)\n","\n","    acc = accuracy_score(y_true, y_pred_classes)\n","    precision = precision_score(y_true, y_pred_classes, average='weighted', zero_division=0)\n","    recall = recall_score(y_true, y_pred_classes, average='weighted', zero_division=0)\n","    f1 = f1_score(y_true, y_pred_classes, average='weighted', zero_division=0)\n","\n","    return acc, precision, recall, f1\n","\n","# ---------------------------\n","# Compute metrics\n","# ---------------------------\n","metrics_a = get_metrics(model_a, test_gen_a)\n","metrics_b = get_metrics(model_b, test_gen_b)\n","\n","# ---------------------------\n","# Comparison table\n","# ---------------------------\n","df = pd.DataFrame({\n","    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score'],\n","    'Model A (MobileNet)': [f\"{m:.4f}\" for m in metrics_a],\n","    'Model B (Ultra-light CNN)': [f\"{m:.4f}\" for m in metrics_b]\n","})\n","\n","print(\"‚úÖ Model Comparison on Test Set\")\n","display(df)\n"],"metadata":{"id":"-eHDZN8bxC6L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"c9zT30C323x2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ---------------------------\n","# Simple Console UI: Plant Leaf Disease Detection\n","# ---------------------------\n","\n","import numpy as np\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.preprocessing import image\n","import os\n","\n","# ‚úÖ Load the saved model\n","MODEL_PATH = '/content/drive/MyDrive/model_a_best_20250930_050137.h5'\n","model = load_model(MODEL_PATH)\n","\n","# ‚úÖ Image parameters (must match training)\n","IMAGE_SIZE = (224, 224)\n","\n","# ‚úÖ Class labels (replace with your actual class names)\n","class_labels = ['Apple___Black_rot', 'Apple___Healthy', 'Corn___Common_rust', 'Corn___Healthy', 'Grape___Esca', 'Grape___Healthy']  # example\n","\n","def predict_leaf(img_path):\n","    if not os.path.exists(img_path):\n","        print(f\"‚ùå File not found: {img_path}\")\n","        return\n","\n","    # Load and preprocess image\n","    img = image.load_img(img_path, target_size=IMAGE_SIZE)\n","    img_array = image.img_to_array(img) / 255.0\n","    img_array = np.expand_dims(img_array, axis=0)\n","\n","    # Predict\n","    preds = model.predict(img_array)\n","    class_idx = np.argmax(preds)\n","    class_name = class_labels[class_idx]\n","\n","    # Determine health\n","    if \"Healthy\" in class_name:\n","        health_status = \"Healthy\"\n","    else:\n","        health_status = \"Diseased\"\n","\n","    print(\"\\n‚úÖ Prediction Result:\")\n","    print(f\"Plant Type / Disease Class: {class_name}\")\n","    print(f\"Leaf Status: {health_status}\")\n","    print(f\"Confidence: {preds[0][class_idx]:.4f}\")\n","\n","# ---------------------------\n","# Console UI loop\n","# ---------------------------\n","\n","while True:\n","    img_path = input(\"\\nEnter path to leaf image (or 'quit' to exit): \")\n","    if img_path.lower() == 'quit':\n","        print(\"Exiting...\")\n","        break\n","    predict_leaf(img_path)\n"],"metadata":{"id":"OIk3zuqxz6rs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"LZ5ds3z-3zGH"},"execution_count":null,"outputs":[]}]}